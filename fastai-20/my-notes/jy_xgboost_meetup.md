# Meetup Oct 2021, XGBoost  

 * Presented in a paper for the first time in 2016.  
   - https://arxiv.org/pdf/1603.02754.pdf 
   - Tianqi Chen and Carlos Guestrin, XGBoost: A Scalable Tree Boosting System.  

### Overview   


### Boosting vs Random Forest  
\(from XGBOOST docs:  https://xgboost.readthedocs.io/en/latest/tutorials/rf.html\)
"XGBoost is normally used to train gradient-boosted decision trees and other gradient boosted models. Random Forests use the same model representation and inference, as gradient-boosted decision trees, but a different training algorithm. One can use XGBoost to train a standalone random forest or use random forest as a base model for gradient boosting."   


### SGBoost software library - supports multiple languages  
Python Dask (parallel) application available.  

### Diagrams of note:  

refers to paper:  

### My contact  
Jennifer E. Yoon  github: https://github.com/JennEYoon/  
email:  jenneyoon@gmail.com  
